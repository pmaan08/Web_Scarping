import scrapy
from scrapy.crawler import CrawlerProcess

url = 'https://www.datacamp.com/courses/all'

class First_Spider(scrapy.Spider):
#start_request method
   name = "first_spider_datacamp_crawler"
   def start_requests(self):
      yield scrapy.Request(url = url_short , callback= self.parse_front)


   def parse_front(self,response):
       #site url & course link
       course_block=response.css('div.course-block')
       course_links=course_block.xpath('./a/@href')
       links_to_follow = course_links.extract()
       for url in links_to_follow:
           yield response.follow(url =url ,callback = self.parse_pages)

   def parse_pages(self,response):
       #course title,link and chapter title
       crs_title = response.xpath('//h1[contains(@class,"title")]/text')
       crs_title_ext=crs_title_ext.extract_first().setup()
       ch_titles = response.css('h4.chapter__title::text')
       ch_titles_ext=[t.strip() for t in ch_titles.extract()]
       #dictionary key value pair
       dc_dict[crs_title_ext]=ch_titles_ext
      
dc_dict=dict()

process = CrawlerProcess()
process.crawl(First_Spider)
process.start()
